{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2828934,"sourceType":"datasetVersion","datasetId":1730328},{"sourceId":14168051,"sourceType":"datasetVersion","datasetId":9031028}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:04:59.983643Z","iopub.execute_input":"2025-12-18T12:04:59.983808Z","iopub.status.idle":"2025-12-18T12:04:59.990034Z","shell.execute_reply.started":"2025-12-18T12:04:59.983793Z","shell.execute_reply":"2025-12-18T12:04:59.989245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom tensorflow.keras.preprocessing import image\n\n\ndataset_path = '/kaggle/input/trashnet/dataset-resized'\n\nall_images = []\nlabels = []\n\nfor category in os.listdir(dataset_path):\n    category_path = os.path.join(dataset_path, category)\n    if os.path.isdir(category_path):\n        for file in os.listdir(category_path):\n            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                image_path = os.path.join(category_path, file)\n                try:\n                    img = cv2.imread(image_path)\n                    if img is None:\n                        print(f\"Skipping corrupted image: {image_path}\")\n                        continue\n                    all_images.append(image_path)\n                    labels.append(category)\n                except Exception as e:\n                    print(f\"Skipping corrupted image {image_path}: {e}\")\n                    continue\n\nprint(f\"Total images found: {len(all_images)}\")\nprint(f\"Categories: {set(labels)}\")\nprint(f\"Image distribution: {dict((label, labels.count(label)) for label in set(labels))}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:04:59.991263Z","iopub.execute_input":"2025-12-18T12:04:59.991474Z","iopub.status.idle":"2025-12-18T12:05:38.768100Z","shell.execute_reply.started":"2025-12-18T12:04:59.991458Z","shell.execute_reply":"2025-12-18T12:05:38.767410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n\n# Split into train (80%) and test (20%)\ntrain_images, test_images, train_labels, test_labels = train_test_split(\n    all_images, labels, test_size=0.2, random_state=42, stratify=labels\n)\n\nlabel_encoder = LabelEncoder()\ntrain_labels_encoded = label_encoder.fit_transform(train_labels)\ntest_labels_encoded = label_encoder.transform(test_labels)\n\ntrain_labels_cat = to_categorical(train_labels_encoded)\ntest_labels_cat = to_categorical(test_labels_encoded)\n\n\n\nprint(f\"Training set: {len(train_images)} images ({len(train_images)/len(all_images)*100:.1f}%)\")\nprint(f\"Testing set: {len(test_images)} images ({len(test_images)/len(all_images)*100:.1f}%)\")\n\nprint(\"\\nLabel distribution in training set:\")\nfor label in set(train_labels):\n    print(f\"  {label}: {train_labels.count(label)}\")\n\nprint(\"\\nLabel distribution in test set:\")\nfor label in set(test_labels):\n    print(f\"  {label}: {test_labels.count(label)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:05:38.769275Z","iopub.execute_input":"2025-12-18T12:05:38.769744Z","iopub.status.idle":"2025-12-18T12:05:38.888845Z","shell.execute_reply.started":"2025-12-18T12:05:38.769723Z","shell.execute_reply":"2025-12-18T12:05:38.888284Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Augmetation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image as keras_image\n\ndef augment_and_load_images(image_paths, labels, target_size, augment=True, target_per_class=500):\n    \"\"\"\n    Load and optionally augment images for TrashNet dataset.\n    Ensures each class has exactly target_per_class images through augmentation.\n    \n    Args:\n        image_paths: List of image file paths\n        labels: List of corresponding labels\n        target_size: Target image size (height, width)\n        augment: Whether to apply data augmentation\n        target_per_class: Target number of images per class (default: 500)\n    \n    Returns:\n        Tuple of (images_array, labels_array)\n    \"\"\"\n    if augment:\n        datagen = ImageDataGenerator(\n            fill_mode='nearest',\n            horizontal_flip=True,\n            shear_range=0.2,\n            rotation_range=40,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            zoom_range=0.2\n        )\n        print(f\"\\n{'='*60}\")\n        print(f\"LOADING TRAINING IMAGES WITH AUGMENTATION\")\n        print(f\"Target: {target_per_class} images per class\")\n        print(f\"{'='*60}\")\n    else:\n        print(f\"\\n{'='*60}\")\n        print(f\"LOADING IMAGES (NO AUGMENTATION)\")\n        print(f\"{'='*60}\")\n    \n    # Group images by class\n    class_images = {}\n    for img_path, label in zip(image_paths, labels):\n        if label not in class_images:\n            class_images[label] = []\n        class_images[label].append(img_path)\n    \n    print(f\"\\nClass distribution (original):\")\n    for label, paths in sorted(class_images.items()):\n        print(f\"  Class {label}: {len(paths)} images\")\n    \n    images_list = []\n    labels_list = []\n    \n    # Process each class\n    for label, img_paths in sorted(class_images.items()):\n        print(f\"\\nProcessing class {label}...\")\n        num_original = len(img_paths)\n        \n        if augment and num_original < target_per_class:\n            # Calculate how many augmentations needed per image\n            augmentations_per_image = (target_per_class // num_original)\n            remainder = target_per_class % num_original\n            \n            print(f\"  Original images: {num_original}\")\n            print(f\"  Target images: {target_per_class}\")\n            print(f\"  Augmentations per image: {augmentations_per_image}\")\n        \n        for idx, img_path in enumerate(img_paths):\n            if (idx + 1) % 50 == 0 or (idx + 1) == num_original:\n                print(f\"  Progress: {idx + 1}/{num_original}\")\n            \n            try:\n                # Load and preprocess image\n                img = keras_image.load_img(img_path, target_size=target_size)\n                img_array = keras_image.img_to_array(img)\n                img_array = img_array / 255.0  # Normalize to [0, 1]\n                \n                # Add original image\n                images_list.append(img_array)\n                labels_list.append(label)\n                \n                if augment and num_original < target_per_class:\n                    # Determine number of augmentations for this specific image\n                    num_augs = augmentations_per_image - 1  # -1 because we already added original\n                    if idx < remainder:\n                        num_augs += 1  # Add extra augmentation to first 'remainder' images\n                    \n                    if num_augs > 0:\n                        img_array_for_aug = img_array * 255.0\n                        img_array_expanded = np.expand_dims(img_array_for_aug, axis=0)\n                        \n                        aug_iterator = datagen.flow(\n                            img_array_expanded,\n                            batch_size=1,\n                            shuffle=False,\n                            seed=42 + idx + label * 10000  # Reproducible augmentations\n                        )\n                        \n                        for _ in range(num_augs):\n                            img_augmented = next(aug_iterator)[0]\n                            img_augmented = img_augmented / 255.0  # Normalize back\n                            images_list.append(img_augmented)\n                            labels_list.append(label)\n                        \n            except Exception as e:\n                print(f\"  Warning: Failed to load {img_path}: {e}\")\n                continue\n        \n        # Count images for this class\n        class_count = sum(1 for l in labels_list if l == label)\n        print(f\"  Final count for class {label}: {class_count} images\")\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"FINAL DATASET SUMMARY\")\n    print(f\"{'='*60}\")\n    print(f\"Total images: {len(images_list)}\")\n    \n    # Show final class distribution\n    unique_labels = sorted(set(labels_list))\n    print(f\"\\nFinal class distribution:\")\n    for label in unique_labels:\n        count = sum(1 for l in labels_list if l == label)\n        print(f\"  Class {label}: {count} images\")\n    print()\n    \n    return np.array(images_list), np.array(labels_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:05:38.889585Z","iopub.execute_input":"2025-12-18T12:05:38.889897Z","iopub.status.idle":"2025-12-18T12:05:38.902870Z","shell.execute_reply.started":"2025-12-18T12:05:38.889881Z","shell.execute_reply":"2025-12-18T12:05:38.902312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images_loaded, train_labels_augmented = augment_and_load_images(\n    train_images,\n    train_labels_encoded,\n    target_size=(224, 224),\n    augment=True,\n    target_per_class=600\n)\n\n\ntest_images_loaded, test_labels_final = augment_and_load_images(\n    test_images,\n    test_labels_encoded,\n    target_size=(224, 224),\n    augment=False,\n    target_per_class=600\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:05:38.904439Z","iopub.execute_input":"2025-12-18T12:05:38.904636Z","iopub.status.idle":"2025-12-18T12:05:59.594450Z","shell.execute_reply.started":"2025-12-18T12:05:38.904615Z","shell.execute_reply":"2025-12-18T12:05:59.593823Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"## Base model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\n\nbase_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False\n\n\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:05:59.595266Z","iopub.execute_input":"2025-12-18T12:05:59.595516Z","iopub.status.idle":"2025-12-18T12:06:03.292292Z","shell.execute_reply.started":"2025-12-18T12:05:59.595494Z","shell.execute_reply":"2025-12-18T12:06:03.291703Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image as keras_image\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n# from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\ndef extract_features_from_arrays(image_arrays, labels, model):\n    \"\"\"\n    Extract features from pre-loaded image arrays.\n    Args:\n        image_arrays: numpy array of images (N, w, h, 3), values in [0, 1]\n        labels: numpy array of labels\n        model: Feature extraction model\n    Returns:\n        features: numpy array of features\n        labels: same labels array\n    \"\"\"\n    features_list = []\n    total = len(image_arrays)\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"EXTRACTING FEATURES\")\n    print(f\"{'='*60}\")\n    print(f\"\\nProcessing {total} images...\")\n    \n    for idx, img_array in enumerate(image_arrays):\n        if (idx + 1) % 100 == 0 or (idx + 1) == total:\n            print(f\"  Progress: {idx + 1}/{total} ({(idx+1)/total*100:.1f}%)\")\n        \n        # Expand dimensions for batch processing\n        img_array = np.expand_dims(img_array, axis=0)\n        \n        # Preprocess (scale back to [0, 255] then normalize)\n        img_array_scaled = img_array * 255.0\n        img_preprocessed = preprocess_input(img_array_scaled)\n        \n        # Extract features\n        features = model.predict(img_preprocessed, verbose=0)\n        features_list.append(features[0])\n    \n    features = np.array(features_list)\n    \n    print(f\"\\nFeature extraction complete!\")\n    print(f\"Features shape: {features.shape}\")\n    print(f\"Labels shape: {labels.shape}\\n\")\n    \n    return features, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:06:03.292998Z","iopub.execute_input":"2025-12-18T12:06:03.293275Z","iopub.status.idle":"2025-12-18T12:06:03.302380Z","shell.execute_reply.started":"2025-12-18T12:06:03.293246Z","shell.execute_reply":"2025-12-18T12:06:03.301753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features, train_labels_final = extract_features_from_arrays(\n    train_images_loaded,\n    train_labels_augmented,\n    model\n)\n\n\ntest_features, test_labels_final = extract_features_from_arrays(\n    test_images_loaded,\n    test_labels_final,\n    model\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:06:03.303098Z","iopub.execute_input":"2025-12-18T12:06:03.303444Z","iopub.status.idle":"2025-12-18T12:10:39.698626Z","shell.execute_reply.started":"2025-12-18T12:06:03.303419Z","shell.execute_reply":"2025-12-18T12:10:39.697796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Classification","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\n# param_grid = {\n#     'C': [7.7,7.76,7.75,7.79],\n#     'gamma': [0.001, 0.0005, 0.0001, 0.00005, 0.00001],\n#     'kernel': ['rbf'],\n# }\n\n\nsvm_classifier = SVC(\n    kernel='rbf',           \n    C=7.7,                 \n    gamma='scale',          \n    probability=True,       \n    class_weight='balanced', \n    random_state=42\n)\n\n#grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=10, scoring='accuracy', verbose=2, n_jobs=-1)\n#grid_search.fit(train_features, train_labels_final)\n#print(f\"Best parameters found: {grid_search.best_params_}\")\n#print(f\"Best cross-validation accuracy: {grid_search.best_score_:.2f}\")\n#svm_classifier = grid_search.best_estimator_\n\nsvm_classifier.fit(train_features, train_labels_final)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:10:39.699423Z","iopub.execute_input":"2025-12-18T12:10:39.699689Z","iopub.status.idle":"2025-12-18T12:11:01.885695Z","shell.execute_reply.started":"2025-12-18T12:10:39.699661Z","shell.execute_reply":"2025-12-18T12:11:01.885083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\n# knn_param_grid = {\n#     'n_neighbors': [3, 5, 7, 9, 11],\n#     'weights': ['uniform', 'distance'],\n#     'metric': ['euclidean', 'cosine']\n# }\n\n# knn_grid_search = GridSearchCV(\n#     estimator=KNeighborsClassifier(),\n#     param_grid=knn_param_grid,\n#     cv=5,\n#     scoring='accuracy',\n#     verbose=2,\n#     n_jobs=-1\n# )\n# knn_grid_search.fit(train_features, train_labels_encoded)\n\nknn_classifier = KNeighborsClassifier(\n    n_neighbors=7,          \n    weights='distance',     \n    algorithm='auto',       \n    metric='minkowski',    \n    p=2,                    \n    n_jobs=-1              \n)\nknn_classifier.fit(train_features, train_labels_final)\n\n# print(f\"Best KNN parameters: {knn_grid_search.best_params_}\")\n# print(f\"Best KNN CV accuracy: {knn_grid_search.best_score_:.2f}\")\n# knn_classifier = knn_grid_search.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:11:01.886534Z","iopub.execute_input":"2025-12-18T12:11:01.886763Z","iopub.status.idle":"2025-12-18T12:11:02.022666Z","shell.execute_reply.started":"2025-12-18T12:11:01.886746Z","shell.execute_reply":"2025-12-18T12:11:02.022110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(\"\\n=== SVM Results ===\")\n\n\nsvm_test_pred = svm_classifier.predict(test_features)\nprint(f\"Test Accuracy: {accuracy_score(test_labels_final, svm_test_pred):.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_labels_final, svm_test_pred, target_names=label_encoder.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:11:02.024423Z","iopub.execute_input":"2025-12-18T12:11:02.024629Z","iopub.status.idle":"2025-12-18T12:11:03.041697Z","shell.execute_reply.started":"2025-12-18T12:11:02.024613Z","shell.execute_reply":"2025-12-18T12:11:03.040833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n=== KNN Results ===\")\n\nknn_test_pred = knn_classifier.predict(test_features)\nprint(f\"Test Accuracy: {accuracy_score(test_labels_final, knn_test_pred):.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(test_labels_final, knn_test_pred, target_names=label_encoder.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:11:03.042583Z","iopub.execute_input":"2025-12-18T12:11:03.042913Z","iopub.status.idle":"2025-12-18T12:11:03.167002Z","shell.execute_reply.started":"2025-12-18T12:11:03.042881Z","shell.execute_reply":"2025-12-18T12:11:03.166412Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image, display\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndef predict_image(image_path, show_image=True, confidence_threshold=0.5):\n    if show_image:\n        display(Image(image_path, width=224))\n    \n    # Load and preprocess image\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_resized = cv2.resize(img, (224, 224))\n    \n    # Normalize to [0, 1] (MATCH YOUR TRAINING PREPROCESSING)\n    img_array = img_resized / 255.0\n    img_array = np.expand_dims(img_array, axis=0).astype('float32')\n    \n    img_array_scaled = img_array * 255.0\n    img_preprocessed = preprocess_input(img_array_scaled)\n    \n    # Extract features\n    features = model.predict(img_preprocessed, verbose=0)\n    \n    # SVM prediction (use features directly)\n    svm_pred = svm_classifier.predict(features)[0]\n    svm_class = label_encoder.inverse_transform([svm_pred])[0]\n    \n    # KNN prediction (use features directly)\n    knn_pred = knn_classifier.predict(features)[0]\n    knn_class = label_encoder.inverse_transform([knn_pred])[0]\n    \n    # Get confidence scores (use features directly)\n    if hasattr(svm_classifier, 'predict_proba'):\n        svm_proba = svm_classifier.predict_proba(features)[0]\n        svm_confidence = max(svm_proba)\n        svm_confidence_pct = svm_confidence * 100\n    else:\n        svm_confidence = None\n        svm_confidence_pct = \"N/A\"\n    \n    knn_proba = knn_classifier.predict_proba(features)[0]\n    knn_confidence = max(knn_proba)\n    knn_confidence_pct = knn_confidence * 100\n    \n    # Apply confidence threshold\n    if svm_confidence is not None and svm_confidence < confidence_threshold:\n        svm_class = \"Unknown Object\"\n    if knn_confidence < confidence_threshold:\n        knn_class = \"Unknown Object\"\n    \n    # Print results\n    print(\"\\n\" + \"=\"*50)\n    print(\"PREDICTION RESULTS\")\n    print(\"=\"*50)\n    print(f\"\\nðŸ”¹ SVM Prediction: {svm_class}\")\n    if svm_confidence_pct != \"N/A\":\n        print(f\"   Confidence: {svm_confidence_pct:.2f}%\")\n        if svm_confidence < confidence_threshold:\n            print(f\"   âš ï¸  Below threshold ({confidence_threshold*100:.0f}%)\")\n    \n    print(f\"\\nðŸ”¹ KNN Prediction: {knn_class}\")\n    print(f\"   Confidence: {knn_confidence_pct:.2f}%\")\n    if knn_confidence < confidence_threshold:\n        print(f\"   âš ï¸  Below threshold ({confidence_threshold*100:.0f}%)\")\n    \n    print(\"=\"*50 + \"\\n\")\n    \n    return svm_class, knn_class\n\n# Test\nsvm_result, knn_result = predict_image(\n    r\"/kaggle/input/test-model/paper4.png\",\n    confidence_threshold=0.5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:15:12.045687Z","iopub.execute_input":"2025-12-18T12:15:12.046284Z","iopub.status.idle":"2025-12-18T12:15:12.175962Z","shell.execute_reply.started":"2025-12-18T12:15:12.046258Z","shell.execute_reply":"2025-12-18T12:15:12.174910Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nimport json\nfrom tensorflow.keras.models import Model\n\n# ===================================\n# SAVE ALL MODELS AND METADATA\n# ===================================\n\nprint(\"Saving models and metadata...\")\n\n# 1. Save the feature extractor model (use SavedModel format, not H5)\nimport tensorflow as tf\ntf.saved_model.save(model, '/kaggle/working/feature_extractor_model')\nprint(\"   âœ“ Feature extractor saved as TensorFlow SavedModel\")\n\n# 2. Save SVM classifier\nprint(\"\\n2. Saving SVM classifier...\")\nwith open('/kaggle/working/svm_classifier.pkl', 'wb') as f:\n    pickle.dump(svm_classifier, f)\nprint(\"   âœ“ SVM classifier saved\")\n\n# 3. Save KNN classifier\nprint(\"\\n3. Saving KNN classifier...\")\nwith open('/kaggle/working/knn_classifier.pkl', 'wb') as f:\n    pickle.dump(knn_classifier, f)\nprint(\"   âœ“ KNN classifier saved\")\n\n# 4. Save label encoder\nprint(\"\\n4. Saving label encoder...\")\nwith open('/kaggle/working/label_encoder.pkl', 'wb') as f:\n    pickle.dump(label_encoder, f)\nprint(\"   âœ“ Label encoder saved\")\n\n# 5. Save metadata (useful information)\nprint(\"\\n5. Saving metadata...\")\nmetadata = {\n    'classes': label_encoder.classes_.tolist(),\n    'num_classes': len(label_encoder.classes_),\n    'input_shape': (224, 224, 3),\n    'feature_shape': train_features.shape[1],\n    'svm_params': {\n        'kernel': 'rbf',\n        'C': 7.7,\n        'gamma': 'scale',\n        'probability': True,\n        'class_weight': 'balanced'\n    },\n    'knn_params': {\n        'n_neighbors': 7,\n        'weights': 'distance',\n        'metric': 'minkowski',\n        'p': 2\n    }\n}\n\nwith open('/kaggle/working/model_metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\nprint(\"   âœ“ Metadata saved\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ALL MODELS SAVED SUCCESSFULLY!\")\nprint(\"=\"*60)\nprint(\"\\nSaved files:\")\nprint(\"  1. /kaggle/working/feature_extractor_model/ (directory)\")\nprint(\"  2. /kaggle/working/svm_classifier.pkl\")\nprint(\"  3. /kaggle/working/knn_classifier.pkl\")\nprint(\"  4. /kaggle/working/label_encoder.pkl\")\nprint(\"  5. /kaggle/working/model_metadata.json\")\nprint(\"\\nDownload all these files from Kaggle to use in your application!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T12:11:03.317620Z","iopub.execute_input":"2025-12-18T12:11:03.317791Z","iopub.status.idle":"2025-12-18T12:11:16.178157Z","shell.execute_reply.started":"2025-12-18T12:11:03.317776Z","shell.execute_reply":"2025-12-18T12:11:16.177462Z"}},"outputs":[],"execution_count":null}]}